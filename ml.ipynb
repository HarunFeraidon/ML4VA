{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import warnings\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, cross_validate, GridSearchCV\n",
        "from pandas.plotting import scatter_matrix  # optional\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from config import api_key\n",
        "from gmplot import gmplot\n",
        "%matplotlib inline\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"ticket_data.csv\")\n",
        "df.dropna(inplace=True)\n",
        "df.head()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n\n",
        "def fix_time(time):\n",
        "    time = str(time).strip().replace(\".\", \"\")\n",
        "    if len(time) == 1:\n",
        "        time = \"0\" + time\n",
        "    if \":\" not in time:\n",
        "        if (len(time)) == 5:\n",
        "            time = time[:-1]\n",
        "        time = time[:-2] + \":\" + time[-2:]\n",
        "    return f\"{'0' * max(5-len(time),0)}{time}:00\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"DateIssued\"] = df[\"DateIssued\"].apply(lambda x: x[:10] if int(x[:2]) <= 21 else np.nan)\n",
        "df[\"TimeIssued\"] = df[\"TimeIssued\"].apply(fix_time)\n",
        "df.head()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.where((df[\"latitude\"] < 38.4) & (df[\"AppealStatus\"] != \"pending\"))\n",
        "df.dropna(inplace=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmap = gmplot.GoogleMapPlotter(df[\"latitude\"].mean(), df[\"longitude\"].mean(), 14)\n",
        "gmap.apikey = api_key\n",
        "# gmap.scatter(df[\"latitude\"], df[\"longitude\"], '#FF0000', size=10, marker=False)\n",
        "gmap.heatmap(df[\"latitude\"], df[\"longitude\"])\n",
        "gmap.draw(\"my_map.html\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = df.iloc[:, [1, 2, 3, 5, 6]]\n",
        "X = df.iloc[:, [3, 5, 6]]  # don't look at date or time right now (interesting strategy, I know).\n",
        "y = df.iloc[:, 4]\n",
        "new_vio = LabelEncoder().fit(X[\"ViolationDescription\"]).transform(X[\"ViolationDescription\"])\n",
        "new_appeal = LabelEncoder().fit(y).transform(y)\n",
        "X[\"ViolationDescription\"] = new_vio\n",
        "y = new_appeal\n",
        "X = StandardScaler().fit(X).transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Linear SVM\": SVC(),\n",
        "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
        "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
        "    \"Neural Net\": MLPClassifier(alpha=1),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n\n",
        "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers=5, verbose=True):\n",
        "    \"\"\"\n",
        "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
        "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
        "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
        "    is because it is very easy to save the whole dictionary with the pickle module.\n",
        "\n",
        "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train.\n",
        "    So it is best to train them on a smaller dataset first and\n",
        "    decide whether you want to comment them out or not based on the test accuracy score.\n",
        "    \"\"\"\n",
        "\n",
        "    dict_models = {}\n",
        "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
        "        t_start = time.clock()\n",
        "        classifier.fit(X_train, Y_train)\n",
        "        t_end = time.clock()\n",
        "\n",
        "        t_diff = t_end - t_start\n",
        "        train_score = classifier.score(X_train, Y_train)\n",
        "        test_score = classifier.score(X_test, Y_test)\n",
        "\n",
        "        dict_models[classifier_name] = {\n",
        "            'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff}\n",
        "        if verbose:\n",
        "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
        "    return dict_models\n",
        "\n\n",
        "def display_dict_models(dict_models, sort_by='test_score'):\n",
        "    cls = [key for key in dict_models.keys()]\n",
        "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
        "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
        "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
        "\n",
        "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls), 4)), columns=[\n",
        "                       'classifier', 'train_score', 'test_score', 'train_time'])\n",
        "    for ii in range(0, len(cls)):\n",
        "        df_.loc[ii, 'classifier'] = cls[ii]\n",
        "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
        "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
        "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
        "\n",
        "    display(df_.sort_values(by=sort_by, ascending=False))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_models = batch_classify(X_train, y_train, X_test, y_test, no_classifiers=8)\n",
        "display_dict_models(dict_models)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=1000)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n\n",
        "def test_svm(svm, X_test, y_test):\n",
        "    predictions = svm.predict(X_test)\n",
        "    acc = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    print(f\"Accuracy:{acc}\\nPrecision:{precision}\\nRecall:{recall}\\nF1 Score:{f1}\")\n",
        "\n\n",
        "test_svm(svm_clf, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# awesome code for modeling http://ataspinar.com/2017/05/26/classification-with-scikit-learn/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}