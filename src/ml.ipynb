{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import warnings\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, cross_validate, GridSearchCV\n",
        "from pandas.plotting import scatter_matrix  # optional\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from src import config\n",
        "from gmplot import gmplot\n",
        "from src import k_means\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/cleaned_data.csv\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = df.iloc[:, [1, 2, 3, 5, 6]]\n",
        "df[\"ViolationDescription\"].value_counts()\n",
        "df.head()\n",
        "X = df.iloc[:, [3, 5, 6, 7, 8]]\n",
        "y = df.iloc[:, 4].apply(lambda x: 1 if x == \"granted\" else 0)\n",
        "x_pipe = ColumnTransformer([\n",
        "    (\"numerical_vals\", StandardScaler(), [\"latitude\", \"longitude\", \"Hour\"]),\n",
        "    (\"categorical_values\", OneHotEncoder(), [\"ViolationDescription\", \"DayIssued\"])\n",
        "])\n",
        "X = x_pipe.fit_transform(X)\n",
        "gps_scaler = StandardScaler()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_classifiers = {\n",
        "    # \"Logistic Regression\": LogisticRegression(),\n",
        "    # \"Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Linear SVM\": SVC(),\n",
        "    \"Non-Linear SVM\": SVC(C=.01, gamma=.1, kernel=\"rbf\"),\n",
        "    # \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
        "    # \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=\"sqrt\", max_depth=50, bootstrap=True),\n",
        "    # \"Neural Net\": MLPClassifier(alpha=1),\n",
        "    # \"Naive Bayes\": GaussianNB()\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers=5, verbose=True):\n",
        "    \"\"\"\n",
        "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
        "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
        "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
        "    is because it is very easy to save the whole dictionary with the pickle module.\n",
        "\n",
        "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train.\n",
        "    So it is best to train them on a smaller dataset first and\n",
        "    decide whether you want to comment them out or not based on the test accuracy score.\n",
        "    \"\"\"\n",
        "\n",
        "    dict_models = {}\n",
        "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
        "        t_start = time.process_time()\n",
        "        classifier.fit(X_train, Y_train)\n",
        "        t_end = time.process_time()\n",
        "\n",
        "        t_diff = t_end - t_start\n",
        "        train_score = classifier.score(X_train, Y_train)\n",
        "        test_score = classifier.score(X_test, Y_test)\n",
        "\n",
        "        dict_models[classifier_name] = {\n",
        "            'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff}\n",
        "        if verbose:\n",
        "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
        "    return dict_models\n",
        "\n",
        "\n",
        "def display_dict_models(dict_models, sort_by='test_score'):\n",
        "    cls = [key for key in dict_models.keys()]\n",
        "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
        "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
        "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
        "\n",
        "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls), 4)), columns=[\n",
        "        'classifier', 'train_score', 'test_score', 'train_time'])\n",
        "    for ii in range(0, len(cls)):\n",
        "        df_.loc[ii, 'classifier'] = cls[ii]\n",
        "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
        "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
        "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
        "\n",
        "    display(df_.sort_values(by=sort_by, ascending=False))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# awesome code for modeling http://ataspinar.com/2017/05/26/classification-with-scikit-learn/\n",
        "dict_models = batch_classify(X_train, y_train, X_test, y_test, no_classifiers=3)\n",
        "display_dict_models(dict_models)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERTUNING SVM\n",
        "\n",
        "\n",
        "def plot_metric(metric, label, i, dolog=False):\n",
        "    plt.subplot(2, 2, i)\n",
        "    if dolog:\n",
        "        plt.plot(np.log(c_values), metric)\n",
        "        plt.xlabel(\"log(C)\")\n",
        "    else:\n",
        "        plt.plot(c_values, metric)\n",
        "        plt.xlabel(\"C\")\n",
        "    plt.title(f\"{label} as a function of C\")\n",
        "    plt.ylabel(\"Score\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "\n",
        "\n",
        "def test_clfs(c):\n",
        "    svm_clf = LinearSVC(C=c, loss=\"hinge\", random_state=42, max_iter=1000)\n",
        "    scores = cross_validate(svm_clf, X_train, y_train,\n",
        "                            scoring=scoring_metrics, cv=3, return_train_score=False)\n",
        "    return (np.mean(scores[\"test_accuracy\"]), np.mean(scores[\"test_precision\"]), np.mean(scores[\"test_recall\"]), np.mean(scores[\"test_f1\"]))\n",
        "\n",
        "\n",
        "c_values = [.001, .01, .1, 1, 10, 100, 1000]\n",
        "results = [test_clfs(c) for c in c_values]\n",
        "accuracies, precisions, recalls, f1s = zip(*results)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "plot_metric(accuracies, \"Accuracy\", 1, True)\n",
        "plot_metric(precisions, \"Precision\", 2, True)\n",
        "plot_metric(recalls, \"Recall\", 3, True)\n",
        "plot_metric(f1s, \"F1-Score\", 4, True)\n",
        "# plt.savefig(\"images/linear_svm.png\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = max(accuracies)\n",
        "ind = accuracies.index(best_acc)\n",
        "best_c = c_values[5]\n",
        "print(best_c)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "               'gamma': [0.0001, 0.001, 0.01, 0.1]}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(kernel=\"rbf\"), params_grid,\n",
        "                           scoring=scoring_metrics, refit=False, return_train_score=False)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "accuracies = list(grid_search.cv_results_[\"mean_test_accuracy\"])\n",
        "precisions = list(grid_search.cv_results_[\"mean_test_precision\"])\n",
        "recalls = list(grid_search.cv_results_[\"mean_test_recall\"])\n",
        "f1s = list(grid_search.cv_results_[\"mean_test_f1\"])\n",
        "nonlinear_c_values = list(grid_search.cv_results_[\"param_C\"])\n",
        "gamma_values = list(grid_search.cv_results_[\"param_gamma\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_3d_metric(ax, metric, label):\n",
        "    ax.scatter(np.log(nonlinear_c_values), np.log(gamma_values), metric)\n",
        "    ax.set_xlabel(\"log(C)\")\n",
        "    ax.set_ylabel(\"log(gamma)\")\n",
        "    ax.set_zlabel(\"Score\")\n",
        "    ax.set_title(f\"{label} as a function of C and gamma\")\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
        "scores = (accuracies, precisions, recalls, f1s)\n",
        "\n",
        "for i in range(1, 5):\n",
        "    ax = fig.add_subplot(220 + i, projection='3d')\n",
        "    plot_3d_metric(ax, scores[i-1], metrics[i-1])\n",
        "plt.savefig(\"images/nonlinear_svm_hypertuning.png\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = (accuracies, precisions, recalls, f1s, nonlinear_c_values, gamma_values)\n",
        "categories = list(zip(*x))\n",
        "categories.sort(key=lambda tup: (-tup[2]))\n",
        "print(*categories[:10], sep=\"\\n\")\n",
        "for i in categories:\n",
        "    print(i)\n",
        "    print(\"-------------------\")\n",
        "best_category = categories[5]\n",
        "best_nonlinear_c = best_category[-2]\n",
        "best_gamma = best_category[-1]\n",
        "print(best_nonlinear_c, best_gamma)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_linear_clf = SVC(C=.01, gamma=.1, kernel=\"rbf\")\n",
        "non_linear_clf.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def test_svm(svm, X_test, y_test):\n",
        "    predictions = svm.predict(X_test)\n",
        "    acc = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    print(f\"Accuracy:{acc}\\nPrecision:{precision}\\nRecall:{recall}\\nF1 Score:{f1}\")\n",
        "\n",
        "\n",
        "test_svm(non_linear_clf, X_test, y_test)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gps_scaler = StandardScaler()\n",
        "# gps_data = gps_scaler.fit_transform(df.iloc[:, [5, 6]])\n",
        "k_m = k_means.K_means(X)\n",
        "centroids = k_m.cluster(8)\n",
        "df[\"Cluster\"] = k_m.closest\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
        "        c=\"Cluster\", cmap=plt.get_cmap(\"jet\"), colorbar=False, figsize=(30, 30), alpha=.4)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmap = gmplot.GoogleMapPlotter(df[\"latitude\"].mean(), df[\"longitude\"].mean(), 14)\n",
        "gmap.apikey = api_key\n",
        "# gmap.scatter(df[\"latitude\"], df[\"longitude\"], '#FF0000', size=10, marker=False)\n",
        "colors = [\"000000\", \"F0F8FF\", \"0000FF\", \"FF0000\", \"FF8C00\", \"006400\", \"FF00FF\", \"FFD700\"]\n",
        "for i, color in enumerate(colors):\n",
        "    sub_df = df.where(df[\"Cluster\"] == i).dropna()\n",
        "    gmap.scatter(sub_df[\"latitude\"], sub_df[\"longitude\"], color, size=10, marker=False)\n",
        "\n",
        "gmap.draw(\"my_map.html\")\n",
        "# gmap.html_color_codes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}